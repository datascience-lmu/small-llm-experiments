{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c86369d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66c2df6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import random\n",
    "import string\n",
    "\n",
    "\n",
    "def add_characters(input: str, char: str = \"x\") -> str:\n",
    "    return \"\".join(\n",
    "        list(\n",
    "            itertools.chain.from_iterable(\n",
    "                zip(input, itertools.repeat(char, times=len(input)))\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def add_words(input: str, word_length: int = 6) -> str:\n",
    "    input_split = input.split(\" \")\n",
    "    junk = []\n",
    "    for _ in range(len(input_split)):\n",
    "        word = \"\"\n",
    "        for _ in range(word_length):\n",
    "            word += random.choice(string.ascii_letters)\n",
    "        junk.append(word)\n",
    "    return \" \".join(list(itertools.chain.from_iterable(zip(input_split, junk))))\n",
    "\n",
    "\n",
    "def split_across_messages(input: str) -> list[str]:\n",
    "    input_split = input.split(\" \")\n",
    "\n",
    "    \n",
    "\n",
    "    return input_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04dbbf9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lxoxrxexmx xixpxsxuxmx xdxoxlxoxrx xsxixtx'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_characters(\"Lorem ipsum dolor sit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be9d8d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lorem LtQyVw ipsum QBIiyY dolor nxLfUA sit DVvpPF'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_words(\"Lorem ipsum dolor sit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "958bd371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lorem', 'ipsum', 'dolor', 'sit']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_across_messages(\"Lorem ipsum dolor sit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588b93eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QwenChatbot:\n",
    "    def __init__(self, model_name: str = \"Qwen/Qwen3-0.6B\", system_prompt: str = \"\"):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "        self.history: list[dict[str, str]] = []\n",
    "\n",
    "        if system_prompt:\n",
    "            self.history.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "\n",
    "    def __call__(self, user_input: str, enable_thinking=True):\n",
    "        messages = self.history + [{\"role\": \"user\", \"content\": user_input}]\n",
    "\n",
    "        text = self.tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True,\n",
    "            enable_thinking=enable_thinking,\n",
    "        )\n",
    "\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\")\n",
    "        response_ids = self.model.generate(**inputs, max_new_tokens=32768)[0][\n",
    "            len(inputs.input_ids[0]) :\n",
    "        ].tolist()\n",
    "\n",
    "        try:\n",
    "            # rindex finding 151668 (</think>)\n",
    "            split_index = len(response_ids) - response_ids[::-1].index(151668)\n",
    "        except ValueError:\n",
    "            split_index = 0\n",
    "\n",
    "        _reasoning_content = self.tokenizer.decode(\n",
    "            response_ids[:split_index], skip_special_tokens=True\n",
    "        ).strip(\"\\n\")\n",
    "        content = self.tokenizer.decode(\n",
    "            response_ids[split_index:], skip_special_tokens=True\n",
    "        ).strip(\"\\n\")\n",
    "\n",
    "        response = self.tokenizer.decode(response_ids, skip_special_tokens=True)\n",
    "\n",
    "        self.history.append({\"role\": \"user\", \"content\": user_input})\n",
    "        self.history.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "        return content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59ddab2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "qwen = QwenChatbot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "157be993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World! How can I assist you today? ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "print(qwen(\"Hello World!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "999234ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It seems like there's a mix of characters and symbols here. Could you clarify what you're asking or if there's a specific task you'd like me to assist with? For example, is this a code, a message, or something else? Let me know! ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "print(qwen(\"xDxox xyxoxux xuxnxdxexrxsxtxaxnxdx xmxex?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97c3b217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'Hello World!'},\n",
       " {'role': 'assistant',\n",
       "  'content': '<think>\\nOkay, the user wrote \"Hello World!\" and I need to respond. Let me start by understanding what they\\'re asking. \"Hello World!\" is a common greeting, so a simple \"Hello World!\" should suffice. But maybe I should add some context to make it more engaging. Let me think... Oh, sometimes people use this as a test or to greet someone. So I can respond with a friendly message. Also, maybe mention that this is a common message to show that I\\'m here. Let me check if there\\'s any specific thing they want to include. The user didn\\'t mention anything else, so a straightforward reply should work. Alright, I\\'ll go with a greeting and a brief explanation.\\n</think>\\n\\nHello World! How can I assist you today? ðŸ˜Š'},\n",
       " {'role': 'user', 'content': 'xDxox xyxoxux xuxnxdxexrxsxtxaxnxdx xmxex?'},\n",
       " {'role': 'assistant',\n",
       "  'content': '<think>\\nOkay, let\\'s see. The user wrote a bunch of characters: \"xDxox xyxoxux xuxnxdxexrxsxtxaxnxdx xmxex?\" \\n\\nFirst, I need to check if there\\'s any pattern or something. The characters are a mix of letters and symbols. Maybe it\\'s a typo or a code. Let me break it down.\\n\\nLooking at the first part: \"xDxox\" â€“ that\\'s x followed by D, then x, then o, x. Then \"xyxoxux\" â€“ x, y, x, o, x, u, x. Then \"xuxnxdxexrxsxtxaxnxdx\" â€“ x, u, x, n, x, d, x, e, r, s, x, t, x, a, x, n, x, d, x. And the last part is \"xmxex\". \\n\\nHmm, maybe it\\'s a code or a message. The user might be testing me or trying to see if I can recognize patterns. Let me think about possible codes. The letters and symbols might be part of a cipher or a code. \\n\\nLooking at the first few letters: \"xDxox\" â€“ maybe it\\'s a message. Then \"xyxoxux\" â€“ similar to the first part. The last part seems to have some letters and symbols. The user might be referring to a code or a cipher. \\n\\nAlternatively, maybe it\\'s a typo. For example, \"xDxox\" could be \"X-D-X-O-X\" â€“ maybe a message. But I need to figure out what\\'s going on here. Since the user is using the \"Hello World!\" response, perhaps they made a mistake in the input. \\n\\nI should ask them to clarify if they want me to assist with a specific task related to the message they provided. Also, check if there\\'s a code they want to decode. Since the response is in Chinese, maybe there\\'s a code in the message that I need to decode. \\n\\nWait, the user wrote \"xDxox xyxoxux xuxnxdxexrxsxtxaxnxdx xmxex?\" which seems to be a mix of characters. Maybe they want me to recognize it as a code or a message. Since I can\\'t read the entire message, I should prompt them to provide more context or ask if they want me to decode it. \\n\\nAlso, check if there\\'s any specific task they have in mind. Since the initial response was \"Hello World!\", maybe they want to confirm that. So I should respond in a friendly way, maybe offer help with any tasks related to the message they provided.\\n</think>\\n\\nIt seems like there\\'s a mix of characters and symbols here. Could you clarify what you\\'re asking or if there\\'s a specific task you\\'d like me to assist with? For example, is this a code, a message, or something else? Let me know! ðŸ˜Š'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qwen.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b71284f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>user\\nHello World!<|im_end|>\\n<|im_start|>assistant\\nHello World! How can I assist you today? ðŸ˜Š<|im_end|>\\n<|im_start|>user\\nxDxox xyxoxux xuxnxdxexrxsxtxaxnxdx xmxex?<|im_end|>\\n<|im_start|>assistant\\n<think>\\nOkay, let\\'s see. The user wrote a bunch of characters: \"xDxox xyxoxux xuxnxdxexrxsxtxaxnxdx xmxex?\" \\n\\nFirst, I need to check if there\\'s any pattern or something. The characters are a mix of letters and symbols. Maybe it\\'s a typo or a code. Let me break it down.\\n\\nLooking at the first part: \"xDxox\" â€“ that\\'s x followed by D, then x, then o, x. Then \"xyxoxux\" â€“ x, y, x, o, x, u, x. Then \"xuxnxdxexrxsxtxaxnxdx\" â€“ x, u, x, n, x, d, x, e, r, s, x, t, x, a, x, n, x, d, x. And the last part is \"xmxex\". \\n\\nHmm, maybe it\\'s a code or a message. The user might be testing me or trying to see if I can recognize patterns. Let me think about possible codes. The letters and symbols might be part of a cipher or a code. \\n\\nLooking at the first few letters: \"xDxox\" â€“ maybe it\\'s a message. Then \"xyxoxux\" â€“ similar to the first part. The last part seems to have some letters and symbols. The user might be referring to a code or a cipher. \\n\\nAlternatively, maybe it\\'s a typo. For example, \"xDxox\" could be \"X-D-X-O-X\" â€“ maybe a message. But I need to figure out what\\'s going on here. Since the user is using the \"Hello World!\" response, perhaps they made a mistake in the input. \\n\\nI should ask them to clarify if they want me to assist with a specific task related to the message they provided. Also, check if there\\'s a code they want to decode. Since the response is in Chinese, maybe there\\'s a code in the message that I need to decode. \\n\\nWait, the user wrote \"xDxox xyxoxux xuxnxdxexrxsxtxaxnxdx xmxex?\" which seems to be a mix of characters. Maybe they want me to recognize it as a code or a message. Since I can\\'t read the entire message, I should prompt them to provide more context or ask if they want me to decode it. \\n\\nAlso, check if there\\'s any specific task they have in mind. Since the initial response was \"Hello World!\", maybe they want to confirm that. So I should respond in a friendly way, maybe offer help with any tasks related to the message they provided.\\n</think>\\n\\nIt seems like there\\'s a mix of characters and symbols here. Could you clarify what you\\'re asking or if there\\'s a specific task you\\'d like me to assist with? For example, is this a code, a message, or something else? Let me know! ðŸ˜Š<|im_end|>\\n<|im_start|>assistant\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qwen.tokenizer.apply_chat_template(\n",
    "    qwen.history, tokenize=False, add_generation_prompt=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9fc7567e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>\n",
      "user\n",
      "\n",
      "\n",
      "Hello\n",
      " World\n",
      "!\n",
      "<|im_end|>\n",
      "\n",
      "\n",
      "<|im_start|>\n",
      "assistant\n",
      "\n",
      "\n",
      "Hello\n",
      " World\n",
      "!\n",
      " How\n",
      " can\n",
      " I\n",
      " assist\n",
      " you\n",
      " today\n",
      "?\n",
      " ï¿½\n",
      "ï¿½\n",
      "<|im_end|>\n",
      "\n",
      "\n",
      "<|im_start|>\n",
      "user\n",
      "\n",
      "\n",
      "xD\n",
      "x\n",
      "ox\n",
      " xy\n",
      "x\n",
      "ox\n",
      "ux\n",
      " x\n",
      "ux\n",
      "n\n",
      "xd\n",
      "x\n",
      "ex\n",
      "rx\n",
      "s\n",
      "xt\n",
      "x\n",
      "ax\n",
      "n\n",
      "xd\n",
      "x\n",
      " x\n",
      "mx\n",
      "ex\n",
      "?\n",
      "<|im_end|>\n",
      "\n",
      "\n",
      "<|im_start|>\n",
      "assistant\n",
      "\n",
      "\n",
      "<think>\n",
      "\n",
      "\n",
      "Okay\n",
      ",\n",
      " let\n",
      "'s\n",
      " see\n",
      ".\n",
      " The\n",
      " user\n",
      " wrote\n",
      " a\n",
      " bunch\n",
      " of\n",
      " characters\n",
      ":\n",
      " \"\n",
      "xD\n",
      "x\n",
      "ox\n",
      " xy\n",
      "x\n",
      "ox\n",
      "ux\n",
      " x\n",
      "ux\n",
      "n\n",
      "xd\n",
      "x\n",
      "ex\n",
      "rx\n",
      "s\n",
      "xt\n",
      "x\n",
      "ax\n",
      "n\n",
      "xd\n",
      "x\n",
      " x\n",
      "mx\n",
      "ex\n",
      "?\"\n",
      " \n",
      "\n",
      "\n",
      "First\n",
      ",\n",
      " I\n",
      " need\n",
      " to\n",
      " check\n",
      " if\n",
      " there\n",
      "'s\n",
      " any\n",
      " pattern\n",
      " or\n",
      " something\n",
      ".\n",
      " The\n",
      " characters\n",
      " are\n",
      " a\n",
      " mix\n",
      " of\n",
      " letters\n",
      " and\n",
      " symbols\n",
      ".\n",
      " Maybe\n",
      " it\n",
      "'s\n",
      " a\n",
      " typo\n",
      " or\n",
      " a\n",
      " code\n",
      ".\n",
      " Let\n",
      " me\n",
      " break\n",
      " it\n",
      " down\n",
      ".\n",
      "\n",
      "\n",
      "Looking\n",
      " at\n",
      " the\n",
      " first\n",
      " part\n",
      ":\n",
      " \"\n",
      "xD\n",
      "x\n",
      "ox\n",
      "\"\n",
      " â€“\n",
      " that\n",
      "'s\n",
      " x\n",
      " followed\n",
      " by\n",
      " D\n",
      ",\n",
      " then\n",
      " x\n",
      ",\n",
      " then\n",
      " o\n",
      ",\n",
      " x\n",
      ".\n",
      " Then\n",
      " \"\n",
      "xy\n",
      "x\n",
      "ox\n",
      "ux\n",
      "\"\n",
      " â€“\n",
      " x\n",
      ",\n",
      " y\n",
      ",\n",
      " x\n",
      ",\n",
      " o\n",
      ",\n",
      " x\n",
      ",\n",
      " u\n",
      ",\n",
      " x\n",
      ".\n",
      " Then\n",
      " \"\n",
      "x\n",
      "ux\n",
      "n\n",
      "xd\n",
      "x\n",
      "ex\n",
      "rx\n",
      "s\n",
      "xt\n",
      "x\n",
      "ax\n",
      "n\n",
      "xd\n",
      "x\n",
      "\"\n",
      " â€“\n",
      " x\n",
      ",\n",
      " u\n",
      ",\n",
      " x\n",
      ",\n",
      " n\n",
      ",\n",
      " x\n",
      ",\n",
      " d\n",
      ",\n",
      " x\n",
      ",\n",
      " e\n",
      ",\n",
      " r\n",
      ",\n",
      " s\n",
      ",\n",
      " x\n",
      ",\n",
      " t\n",
      ",\n",
      " x\n",
      ",\n",
      " a\n",
      ",\n",
      " x\n",
      ",\n",
      " n\n",
      ",\n",
      " x\n",
      ",\n",
      " d\n",
      ",\n",
      " x\n",
      ".\n",
      " And\n",
      " the\n",
      " last\n",
      " part\n",
      " is\n",
      " \"\n",
      "x\n",
      "mx\n",
      "ex\n",
      "\".\n",
      " \n",
      "\n",
      "\n",
      "Hmm\n",
      ",\n",
      " maybe\n",
      " it\n",
      "'s\n",
      " a\n",
      " code\n",
      " or\n",
      " a\n",
      " message\n",
      ".\n",
      " The\n",
      " user\n",
      " might\n",
      " be\n",
      " testing\n",
      " me\n",
      " or\n",
      " trying\n",
      " to\n",
      " see\n",
      " if\n",
      " I\n",
      " can\n",
      " recognize\n",
      " patterns\n",
      ".\n",
      " Let\n",
      " me\n",
      " think\n",
      " about\n",
      " possible\n",
      " codes\n",
      ".\n",
      " The\n",
      " letters\n",
      " and\n",
      " symbols\n",
      " might\n",
      " be\n",
      " part\n",
      " of\n",
      " a\n",
      " cipher\n",
      " or\n",
      " a\n",
      " code\n",
      ".\n",
      " \n",
      "\n",
      "\n",
      "Looking\n",
      " at\n",
      " the\n",
      " first\n",
      " few\n",
      " letters\n",
      ":\n",
      " \"\n",
      "xD\n",
      "x\n",
      "ox\n",
      "\"\n",
      " â€“\n",
      " maybe\n",
      " it\n",
      "'s\n",
      " a\n",
      " message\n",
      ".\n",
      " Then\n",
      " \"\n",
      "xy\n",
      "x\n",
      "ox\n",
      "ux\n",
      "\"\n",
      " â€“\n",
      " similar\n",
      " to\n",
      " the\n",
      " first\n",
      " part\n",
      ".\n",
      " The\n",
      " last\n",
      " part\n",
      " seems\n",
      " to\n",
      " have\n",
      " some\n",
      " letters\n",
      " and\n",
      " symbols\n",
      ".\n",
      " The\n",
      " user\n",
      " might\n",
      " be\n",
      " referring\n",
      " to\n",
      " a\n",
      " code\n",
      " or\n",
      " a\n",
      " cipher\n",
      ".\n",
      " \n",
      "\n",
      "\n",
      "Alternatively\n",
      ",\n",
      " maybe\n",
      " it\n",
      "'s\n",
      " a\n",
      " typo\n",
      ".\n",
      " For\n",
      " example\n",
      ",\n",
      " \"\n",
      "xD\n",
      "x\n",
      "ox\n",
      "\"\n",
      " could\n",
      " be\n",
      " \"\n",
      "X\n",
      "-D\n",
      "-X\n",
      "-O\n",
      "-X\n",
      "\"\n",
      " â€“\n",
      " maybe\n",
      " a\n",
      " message\n",
      ".\n",
      " But\n",
      " I\n",
      " need\n",
      " to\n",
      " figure\n",
      " out\n",
      " what\n",
      "'s\n",
      " going\n",
      " on\n",
      " here\n",
      ".\n",
      " Since\n",
      " the\n",
      " user\n",
      " is\n",
      " using\n",
      " the\n",
      " \"\n",
      "Hello\n",
      " World\n",
      "!\"\n",
      " response\n",
      ",\n",
      " perhaps\n",
      " they\n",
      " made\n",
      " a\n",
      " mistake\n",
      " in\n",
      " the\n",
      " input\n",
      ".\n",
      " \n",
      "\n",
      "\n",
      "I\n",
      " should\n",
      " ask\n",
      " them\n",
      " to\n",
      " clarify\n",
      " if\n",
      " they\n",
      " want\n",
      " me\n",
      " to\n",
      " assist\n",
      " with\n",
      " a\n",
      " specific\n",
      " task\n",
      " related\n",
      " to\n",
      " the\n",
      " message\n",
      " they\n",
      " provided\n",
      ".\n",
      " Also\n",
      ",\n",
      " check\n",
      " if\n",
      " there\n",
      "'s\n",
      " a\n",
      " code\n",
      " they\n",
      " want\n",
      " to\n",
      " decode\n",
      ".\n",
      " Since\n",
      " the\n",
      " response\n",
      " is\n",
      " in\n",
      " Chinese\n",
      ",\n",
      " maybe\n",
      " there\n",
      "'s\n",
      " a\n",
      " code\n",
      " in\n",
      " the\n",
      " message\n",
      " that\n",
      " I\n",
      " need\n",
      " to\n",
      " decode\n",
      ".\n",
      " \n",
      "\n",
      "\n",
      "Wait\n",
      ",\n",
      " the\n",
      " user\n",
      " wrote\n",
      " \"\n",
      "xD\n",
      "x\n",
      "ox\n",
      " xy\n",
      "x\n",
      "ox\n",
      "ux\n",
      " x\n",
      "ux\n",
      "n\n",
      "xd\n",
      "x\n",
      "ex\n",
      "rx\n",
      "s\n",
      "xt\n",
      "x\n",
      "ax\n",
      "n\n",
      "xd\n",
      "x\n",
      " x\n",
      "mx\n",
      "ex\n",
      "?\"\n",
      " which\n",
      " seems\n",
      " to\n",
      " be\n",
      " a\n",
      " mix\n",
      " of\n",
      " characters\n",
      ".\n",
      " Maybe\n",
      " they\n",
      " want\n",
      " me\n",
      " to\n",
      " recognize\n",
      " it\n",
      " as\n",
      " a\n",
      " code\n",
      " or\n",
      " a\n",
      " message\n",
      ".\n",
      " Since\n",
      " I\n",
      " can\n",
      "'t\n",
      " read\n",
      " the\n",
      " entire\n",
      " message\n",
      ",\n",
      " I\n",
      " should\n",
      " prompt\n",
      " them\n",
      " to\n",
      " provide\n",
      " more\n",
      " context\n",
      " or\n",
      " ask\n",
      " if\n",
      " they\n",
      " want\n",
      " me\n",
      " to\n",
      " decode\n",
      " it\n",
      ".\n",
      " \n",
      "\n",
      "\n",
      "Also\n",
      ",\n",
      " check\n",
      " if\n",
      " there\n",
      "'s\n",
      " any\n",
      " specific\n",
      " task\n",
      " they\n",
      " have\n",
      " in\n",
      " mind\n",
      ".\n",
      " Since\n",
      " the\n",
      " initial\n",
      " response\n",
      " was\n",
      " \"\n",
      "Hello\n",
      " World\n",
      "!\",\n",
      " maybe\n",
      " they\n",
      " want\n",
      " to\n",
      " confirm\n",
      " that\n",
      ".\n",
      " So\n",
      " I\n",
      " should\n",
      " respond\n",
      " in\n",
      " a\n",
      " friendly\n",
      " way\n",
      ",\n",
      " maybe\n",
      " offer\n",
      " help\n",
      " with\n",
      " any\n",
      " tasks\n",
      " related\n",
      " to\n",
      " the\n",
      " message\n",
      " they\n",
      " provided\n",
      ".\n",
      "\n",
      "</think>\n",
      "\n",
      "\n",
      "\n",
      "It\n",
      " seems\n",
      " like\n",
      " there\n",
      "'s\n",
      " a\n",
      " mix\n",
      " of\n",
      " characters\n",
      " and\n",
      " symbols\n",
      " here\n",
      ".\n",
      " Could\n",
      " you\n",
      " clarify\n",
      " what\n",
      " you\n",
      "'re\n",
      " asking\n",
      " or\n",
      " if\n",
      " there\n",
      "'s\n",
      " a\n",
      " specific\n",
      " task\n",
      " you\n",
      "'d\n",
      " like\n",
      " me\n",
      " to\n",
      " assist\n",
      " with\n",
      "?\n",
      " For\n",
      " example\n",
      ",\n",
      " is\n",
      " this\n",
      " a\n",
      " code\n",
      ",\n",
      " a\n",
      " message\n",
      ",\n",
      " or\n",
      " something\n",
      " else\n",
      "?\n",
      " Let\n",
      " me\n",
      " know\n",
      "!\n",
      " ï¿½\n",
      "ï¿½\n",
      "<|im_end|>\n",
      "\n",
      "\n",
      "<|im_start|>\n",
      "assistant\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "token =qwen.tokenizer.apply_chat_template(\n",
    "    qwen.history, tokenize=True, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "for t in token:\n",
    "    print(qwen.tokenizer.decode(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504af052",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
